{"cells":[{"cell_type":"markdown","metadata":{"id":"Ok6dcWmrvpYo"},"source":["##1.2 Install and load libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ksHNoiaevznl"},"outputs":[],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"moc3SHp-k2Ip"},"outputs":[],"source":["import wandb\n","import pandas as pd\n","import numpy as np\n","import tempfile\n","import logging\n","import os"]},{"cell_type":"markdown","metadata":{"id":"Nh8AgArRwDyI"},"source":["##1.3 Preprocessing"]},{"cell_type":"markdown","metadata":{"id":"ejdJosLcwJtK"},"source":["###1.3.1 Download raw_data artifact from Wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qBZ3IMiY9aD9"},"outputs":[],"source":["# Login to Weights & Biases\n","!wandb login --relogin"]},{"cell_type":"code","source":["input_artifact=\"diabetes_decision_tree/raw_data.csv:latest\"\n","artifact_name=\"preprocessed_data.csv\"\n","artifact_type=\"clean_data\"\n","artifact_description=\"Data after preprocessing\""],"metadata":{"id":"9fzT-QJCTmCv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###1.3.2 Setup your wandb project and clean the dataset"],"metadata":{"id":"FL_dfwffT4wv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"KO5Webex9bDY"},"outputs":[],"source":["# create a new job_type\n","run = wandb.init(project=\"diabetes_decision_tree\", job_type=\"process_data\")"]},{"cell_type":"code","source":["# donwload the latest version of artifact raw_data.csv\n","artifact = run.use_artifact(input_artifact)\n","\n","# create a dataframe from the artifact\n","df = pd.read_csv(artifact.file())"],"metadata":{"id":"HxlKpSVvUuVj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFlDhOKF9gk_"},"outputs":[],"source":["# Delete duplicated rows\n","df.drop_duplicates(inplace=True)\n","\n","# Generate a \"clean data file\"\n","df.to_csv(artifact_name,index=False)"]},{"cell_type":"code","source":["#df['New_Glucose_Class'] = pd.cut(x=df['Glucose'], bins=[0,139,200],labels = [\"Normal\",\"Prediabetes\"])\n","#df['New_BMI_Range'] = pd.cut(x=df['BMI'], bins=[0,18.5,24.9,29.9,100],labels = [\"Underweight\",\"Healty\",\"Overweight\",\"Obese\"])\n","#df['New_BloodPressure'] = pd.cut(x=df['BloodPressure'], bins=[0,79,89,123],labels = [\"Normal\",\"HS1\",\"HS2\"])\n","#df['New_SkinThickness'] = df['SkinThickness'].apply(lambda x: 1 if x <= 18.0 else 0)\n","df['New_BMI_Range'] = np.where(df['BMI'] < 18.5, \"Underweight\", np.where(df['BMI'] < 24.9, \"Healty\", np.where(df['BMI'] < 29.9, \"Overweight\", \"Obese\")))\n","df['New_Glucose_Class'] = np.where(df['Glucose'] < 139, \"Normal\", \"Prediabetes\")\n","df['New_BloodPressure'] = np.where(df['BloodPressure'] < 79, \"Normal\", np.where(df['BloodPressure'] < 89, \"HS1\", \"HS2\"))\n","df.head()"],"metadata":{"id":"SxBduLSuFTBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes"],"metadata":{"id":"i_pOe2DBbTl3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def one_hot_encoder(dataframe, categorical_columns, nan_as_category=False):\n","    original_columns = list(dataframe.columns)\n","    dataframe = pd.get_dummies(dataframe, columns=categorical_columns,dummy_na=nan_as_category, drop_first=True)\n","    new_columns = [col for col in dataframe.columns if col not in original_columns]\n","    return dataframe, new_columns"],"metadata":{"id":"KLbi9qTIE-w5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"tsjYK7KyFYwJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# configure logging\n","logging.basicConfig(level=logging.INFO,\n","                    format=\"%(asctime)s %(message)s\",\n","                    datefmt='%d-%m-%Y %H:%M:%S')\n","\n","# reference for a logging obj\n","logger = logging.getLogger()\n","with tempfile.TemporaryDirectory() as tmp_dir:\n","        temp_path = os.path.join(tmp_dir, artifact_name)\n","        df.to_csv(temp_path,index=False)\n","\n","        artifact = wandb.Artifact(name=artifact_name,\n","                                  type=artifact_type,\n","                                  description=\"pre processed data\",\n","        )\n","        \n","        artifact.add_file(temp_path)\n","\n","        logger.info(\"Logging artifact\")\n","        run.log_artifact(artifact)\n","\n","        # This waits for the artifact to be uploaded to W&B. If you\n","        # do not add this, the temp directory might be removed before\n","        # W&B had a chance to upload the datasets, and the upload\n","        # might fail\n","        artifact.wait()"],"metadata":{"id":"4VEGDrqzd44q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"D3bLQYH5d4v8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpAAKYkx-FQc"},"outputs":[],"source":["# Upload the artifact to Wandb\n","run.log_artifact(artifact)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IW6vFqc9-Alf"},"outputs":[],"source":["# close the run\n","# waiting a while after run the previous cell before execute this\n","run.finish()"]},{"cell_type":"code","source":[""],"metadata":{"id":"EiN86Gu1VKLL"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"preprocessing.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}